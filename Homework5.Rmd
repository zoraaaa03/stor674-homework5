---
title: "Homework 5: Version Control, Containerization, and HPC"
author: "STOR 674"
date: "Due: 11/21/2025"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: united
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Overview

This homework will test your knowledge of version control with Git/GitHub, containerization with Docker, and high-performance computing with Apptainer and Slurm. You will:

1. Answer conceptual questions about Git and GitHub
2. **Create a GitHub repository and version control your Docker image build process (with branching and merging)**
3. Build a Docker image for the Linux environment and push it to Docker Hub
4. Download and run the image on Longleaf using Apptainer and Slurm

**Note:** You may be working on macOS or Windows, but you'll be building Linux containers that will run on Longleaf's Linux HPC environment.

**Total Points: 100**

**Important:** You will need to submit:
- A PDF/HTML version of this completed Rmd file with your answers
- A link to your GitHub repository
- A link to your Docker Hub image
- Your Slurm job script
- Screenshot/output of your Slurm job completion

---

# Part 1: Git and GitHub Concepts (20 points)

## Question 1.1: Understanding Commits (5 points)

**a)** (3 points) What does a commit do in Git? Explain what information is stored in a commit.

**Answer:**

A commit in Git creates a snapshot of the entire project at a specific point in time. Each commit stores the complete state of all tracked files (a full snapshot rather than just the differences), along with metadata such as the authors' names and emails, the time stamp of when the commit was made, and the commit message describing the changes. It also includes a unique SHA-1 hash that identifies the commit, as well as pointers to its parent commit or commits, which together form the project’s history chain.


**b)** (2 points) Why is it important to write descriptive commit messages? Provide an example of a good commit message and a bad commit message.

**Answer:**

Writing descriptive commit messages is important because it makes the project history clear and useful for both you and your collaborators. Good messages help developers understand what changed and why, speed up debugging by making it easier to locate relevant commits, and improve long-term maintainability when revisiting code months later. Following a standard structure—such as a short summary under 50 characters followed by an optional detailed explanation—helps keep commit messages concise and informative.

Good commit message example: "Fix RestartCleaner naming assumption for restart files"

Bad commit message example: "update; fix"

## Question 1.2: Branching in Git (10 points)

**a)** (5 points) Explain how branching works in Git. What happens when you create a new branch? What command would you use to create a new branch called `feature-analysis` and switch to it?

**Answer:**

Branching in Git works by creating a new pointer to a specific commit rather than copying the entire project. When a new branch is created, Git simply adds a new reference that initially points to the same commit as the current branch (such as main). The two branches diverge only when new commits are made, with each branch pointer moving independently.

To create and switch to a new branch called feature-analysis, you can use a single command:

`git checkout -b feature-analysis`

Or perform the two steps separately:

`git branch feature-analysis`; `git checkout feature-analysis`.

**b)** (5 points) Git branching is often described as "super lightweight" compared to other version control systems. Explain why Git branching is lightweight. (Hint: Think about how Git stores branches and what happens under the hood when you create a branch.)

**Answer:**

Git branching is "super lightweight" because branches are just pointers that point to specific commits, not copies of the entire code base. 

Unlike other version control systems (like SVN) that create branches by copying all project files to a new directory—which can take minutes for large projects and consume gigabytes of space. Git creates a branch instantly by simply writing a new pointer file.

All branches share the same repository objects (commits, trees, blobs) and only the pointer moves as new commits are made. This makes creating, switching, and deleting branches nearly instantaneous operations regardless of project size.


## Question 1.3: Merging Branches (5 points)

**a)** (3 points) What is the purpose of merging branches? Describe the steps you would take to merge a branch called `feature-analysis` into the `main` branch.

**Answer:**

The purpose of merging branches is to integrate changes from one branch into another, typically bringing feature work back into the main branch. It keeps the main branch stable, enables parallel development, allows for code reviews through pull requests, provides roll back safety, and maintains project history.

Steps to merge feature-analysis into main (local merge):
1. Switch to the target branch: `git checkout main`
2. Ensure main is up-to-date: `git pull origin main` (if working with remote)
3. Merge the feature branch: `git merge feature-analysis`
4. Push the updated main to remote: `git push origin main` (optional)

In collaborative environments, merging is often done via Pull Requests on GitHub/GitLab, which adds code review and CI testing before the merge, rather than direct local merging.

**b)** (2 points) What is a merge conflict and when does it occur?

**Answer:**

A merge conflict occurs when Git cannot automatically merge changes from different branches 
because the same part of a file has been modified in incompatible ways on both branches. 
Git doesn't know which version to keep, so it requires human intervention to resolve.

Merge conflicts happen when:
1. Two branches modify the same lines in a file differently
2. One branch deletes a file while another branch modifies it
3. Both branches add different content at the same location in a file

To avoid merge conflicts:
1. Pull latest changes frequently: `git pull origin main`
2. Keep branches short-lived and merge often
3. Communicate with team members about who's working on which files
4. Make small, focused commits that are easier to merge
5. Regularly sync your feature branch with main to catch conflicts early


---

# Part 2: Docker Image Creation and Deployment with Version Control (50 points)

In this section, you will create a Docker image that can run the `compute_bench.py` script (which you used in Homework 2), which benchmarks CPU/GPU performance using PyTorch. **You will version control the entire process using Git and GitHub, practicing branching and merging workflows.**

**Important Note on Operating Systems:** You may be working on macOS or Windows, but Docker containers run Linux by default. You will be building a **Linux-based container** that will run on Longleaf (which is also Linux). Docker handles the cross-platform compatibility automatically, so your Linux container built on macOS/Windows will work seamlessly on Longleaf's Linux environment.

## Question 2.0: GitHub Repository Setup (5 points)

Before building your Docker image, you will set up version control for your project.

**a)** (1 points) Create a new GitHub repository called `stor674-homework5` (or similar name). Initialize it with a README. Provide the GitHub repository URL.

**GitHub Repository URL:**

`https://github.com/zoraaaa03/stor674-homework5`


**b)** (2 points) Clone the repository to your local machine, add the provided files (`compute_bench.py`, this `Homework5.Rmd`), and make your initial commit. What commands did you use?

**Answer:**

```bash
# Commands you used
cd /Users/zoraachen/Desktop/Fall\ 2025/STOR\ 674/HWs
git clone https://github.com/zoraaaa03/stor674-homework5.git
cd stor674-homework5
cp ~/Desktop/Fall\ 2025/STOR\ 674/HWs/Homework5/compute_bench.py .
cp ~/Desktop/Fall\ 2025/STOR\ 674/HWs/Homework5/Homework5.Rmd .
git status
git add compute_bench.py Homework5.Rmd
git commit -m "Add compute_bench.py and Homework5.Rmd files"
git push origin main

```

**c)** (2 points) Create a new branch called `docker-build` where you will develop your Dockerfile. What command did you use? Why is it good practice to use a separate branch for development instead of working directly on `main`?

**Answer:**

```bash
# Command to create and switch to branch
(base) zoraachen@Mac stor674-homework5 % git checkout -b docker-build
Switched to a new branch 'docker-build'
(base) zoraachen@Mac stor674-homework5 % git branch
* docker-build
  main

```

**Explanation:**

<!-- Why use a separate branch? -->
It's good practice to use a separate branch for development instead of working directly on main due to:

1. Preserves main stability: The main branch remains in a working, deployable state while experimental development happens on feature branches. This ensures other team members can always pull and run functional code from main.
2. Safe experimentation: You can freely test, break things, and make multiple commits on the development branch without affecting the production-ready code. If the Docker configuration fails, main is still intact.
3. Clear history: All Docker-related commits are grouped in one branch, making the development history easy to follow and review.
4. Easy rollback: If something goes wrong, you can simply delete the branch or revert changes without impacting the stable main branch.

## Question 2.1: Understanding compute_bench.py (5 points)

**a)** (3 points) Read the `compute_bench.py` script. What does this script do? What is its main purpose?

**Answer:**

This script is a performance benchmarking tool that compares CPU and GPU computational speeds using `PyTorch`. It generates large arrays of random numbers (\(10^7\) and \(10^8\) elements) and computes their fourth power, measuring the execution time on both CPU and GPU (if available). The main purpose is to demonstrate the performance advantage of GPU computing for large-scale tensor operations, which is crucial for machine learning and scientific computing. Additionally, it generates a small sample of random numbers and saves them to a file for verification.


**b)** (2 points) What Python packages does `compute_bench.py` require?

**Answer:**

The script requires two packages: 

1. `torch (PyTorch)`: for tensor computations and GPU support
2. `time`: Python standard library for measuring execution time


## Question 2.2: Create a Dockerfile (10 points)

Create a Dockerfile that:
- Uses an appropriate **Linux-based** base image with Python 3.9 or later
- Installs the required Python packages (PyTorch with CUDA support for GPU computing)
- Copies `compute_bench.py` into the container
- Sets the default command to run the script

**Important Considerations:**

- **Operating System**: Even if you're on macOS or Windows, Docker will build a Linux container. Use Linux base images (e.g., `python:3.9-slim` is based on Debian Linux).

- **CUDA Support**: Longleaf has NVIDIA GPUs. To enable GPU support in your container:
  - Option 1: Use official PyTorch image with CUDA: `pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime`
  - Option 2: Install PyTorch with CUDA support: `pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118`
  - Note: The container itself doesn't need NVIDIA drivers (Longleaf provides those), but PyTorch needs to be CUDA-aware.

- **Testing Locally**: If your computer doesn't have an NVIDIA GPU, the container will still build and run (it will just use CPU). On Longleaf with GPU nodes, it will automatically detect and use the GPU.

**Instructions:**

1. Make sure you're on the `docker-build` branch
2. Create a file named `Dockerfile` in your repository
3. Write the Dockerfile content below:

```dockerfile
# Paste your Dockerfile content here:
# Use official PyTorch image with CUDA support
FROM pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime

# Set working directory
WORKDIR /app

# Copy the Python script into container
COPY compute_bench.py /app/

# Set the default command to run the script
CMD ["python", "compute_bench.py"]
```

**Grading Criteria:**
- Appropriate Linux base image selection (2 points)
- CUDA-enabled PyTorch installation (4 points)
- Proper file copying (2 points)
- Correct CMD or ENTRYPOINT (2 points)

## Question 2.3: Build and Test Docker Image (10 points)

**a)** (3 points) What command did you use to build your Docker image? Include the full command and explain each part.

**Answer:**

```bash
# Your command here
docker build -t stor674-benchmark .
```

**Explanation:**

- `docker build`: The Docker command to build an image from a Dockerfile
- `-t stor674-benchmark`: The -t flag tags (names) the image as "stor674-benchmark" for easy reference later. Without this tag, Docker would only assign a random ID to the image
- `.`: The dot specifies the build context: the current directory where Docker should look for the Dockerfile and any files that need to be copied into the image

The command reads the Dockerfile in the current directory, executes each instruction sequentially (downloading base image, setting working directory, copying files), and creates a new Docker image named stor674-benchmark.


**b)** (4 points) What command did you use to run your Docker image locally to test it? Include the output you received.

**Answer:**

```bash
# Your command here
docker run stor674-benchmark

```

**Output:**

```
# Paste the output here
(base) zoraachen@Mac stor674-homework5 % docker run stor674-benchmark
WARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested
No GPU available, running on CPU only

CPU Computations:
Time for 10,000,000 elements: 0.2306 seconds
Time for 100,000,000 elements: 2.3022 seconds

Small sample of 10 random numbers:
tensor([-0.1326, -1.5500,  1.1859,  1.5597,  0.7008, -0.4011, -1.1648,  0.1153,
        -0.3273, -0.3363])

Saved data to mydata.pt

```

**c)** (3 points) Were there any issues you encountered during the build or test? How did you resolve them?

**Answer:**

The main issue encountered was a platform architecture warning: "The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8)". While Docker Desktop on Mac can handle this through emulation for local testing, this becomes a critical issue when deploying to x86_64 HPC systems like Longleaf.

The warning indicated that my ARM-based Mac was building ARM64 images by default, which would not be compatible with Longleaf's AMD64 architecture. 

Resolution: This requires using Docker buildx to explicitly build for the linux/amd64 platform:
```bash
docker buildx build --platform linux/amd64 -t zoraazhouaa/stor674-benchmark:latest --push .
```
This ensures the image is built for the correct architecture that will work on both local 
testing (through emulation) and on the target HPC system.


## Question 2.4: Version Control Your Docker Build (10 points)

Now that you have a working Dockerfile, let's commit it and merge it into the main branch.

**a)** (3 points) On your `docker-build` branch, add and commit your Dockerfile with a descriptive commit message. What commands did you use?

**Answer:**

```bash
# Commands to add and commit Dockerfile
git status
git add Dockerfile
git commit -m "Add Dockerfile with CUDA-enabled PyTorch for compute benchmark"


```

**b)** (4 points) Switch to the `main` branch and merge the `docker-build` branch into it. What commands did you use? Paste the merge message or output.

**Answer:**

```bash
# Commands to switch branch and merge
git checkout main
git merge docker-build

```

**Merge Output:**

```
Updating 64f9973..850f557
Fast-forward
 Dockerfile | 11 +++++++++++
 1 file changed, 11 insertions(+)
 create mode 100644 Dockerfile

```

**c)** (3 points) Push your changes to GitHub. Verify that your repository now contains the Dockerfile on the main branch. What command did you use to push?

**Answer:**

```bash
# Command to push to GitHub
git push origin main

```

**Verification:** Visit your GitHub repository in a web browser and confirm the Dockerfile is visible. ✓


## Question 2.5: Push to Docker Hub (10 points)

**a)** (3 points) Create a Docker Hub account (if you don't have one) and provide your Docker Hub username.

**Docker Hub Username:**

<!-- Your username here -->
zoraazhouaa


**b)** (4 points) Tag your image appropriately and push it to Docker Hub. What commands did you use?

**Answer:**

```bash
# Commands you used
docker login
docker tag stor674-benchmark zoraazhouaa/stor674-benchmark:latest
docker push zoraazhouaa/stor674-benchmark:latest
```



**c)** (3 points) Provide the full Docker Hub image URL/name that others can use to pull your image.

**Image URL:**

```
# Format: username/imagename:tag
# Docker pull command format:
zoraazhouaa/stor674-benchmark:latest

# Docker Hub web page:
https://hub.docker.com/r/zoraazhouaa/stor674-benchmark
```

---

# Part 3: Apptainer and Slurm on Longleaf (30 points)

In this section, you will download your Docker image using Apptainer on UNC's Longleaf cluster and submit a job using Slurm. Remember: your Linux container built on macOS/Windows will run seamlessly on Longleaf's Linux environment.

## Question 3.1: Understanding Apptainer (5 points)

**a)** (3 points) What is Apptainer (formerly Singularity) and why is it used on HPC systems instead of Docker?

**Answer:**

Apptainer is a container runtime designed specifically for HPC environments. It's used instead of Docker on HPC systems because:

1. Security: Docker requires root/sudo privileges to run containers, which is a security risk in multi-user HPC environments. Apptainer runs containers as regular users without elevated privileges.

2. Integration: Apptainer integrates seamlessly with HPC schedulers like Slurm and preserves the user's environment (UID, GID, home directory).

3. Compatibility: Apptainer can directly use Docker images from Docker Hub, converting them to its own `.sif` format automatically.

4. Performance: Designed for HPC workloads with minimal overhead and support for parallel computing frameworks like MPI. 


**b)** (2 points) What does "Bring Your Own Environment" (BYOE) mean in the context of HPC and containers?

**Answer:**

It means users can package their complete software environment in a container and run it on any HPC system. This ensures:

- Reproducibility: Same environment everywhere
- Portability: Works across different HPC clusters  
- Flexibility: Users control their software stack without needing admin help
- Consistency: Development environment matches production environment

Instead of relying on system administrators to install specific software versions, users bring their pre-configured environment in a container.


## Question 3.2: Convert Docker Image to Apptainer (10 points)

**a)** (5 points) Log into Longleaf and use Apptainer to pull your Docker image from Docker Hub. What command did you use?

**Answer:**

```bash
# Command to pull/convert Docker image to Apptainer
module load apptainer
apptainer pull docker://zoraazhouaa/stor674-benchmark:latest

```

**b)** (3 points) What is the name of the Apptainer image file (.sif) that was created?

**Answer:**

```
# Filename here
stor674-benchmark_latest.sif
```

**c)** (2 points) Test your Apptainer image interactively. What command did you use to run it?

**Answer:**

```bash
# Command to run Apptainer image
PYTHONPATH="" PYTHONNOUSERSITE=1 apptainer exec --no-home stor674-benchmark_latest.sif python /app/compute_bench.py

```

## Question 3.3: Create Slurm Job Script (12 points)

Create a Slurm job script that runs your containerized `compute_bench.py` using Apptainer.

**Hint:** If you want to test with GPU support on Longleaf, you'll need to:
- Request a GPU partition (e.g., `#SBATCH -p gpu`)
- Request GPU resources (e.g., `#SBATCH --gres=gpu:1`)
- Your CUDA-enabled PyTorch in the container will automatically use the GPU!

**Instructions:**

1. Create a file named `run_compute_bench.sh` in your GitHub repository
2. Include appropriate Slurm directives (partition, time, memory, etc.)
3. Load necessary modules (if needed)
4. Run the Apptainer container

**Your Slurm Script:**

```bash
#!/bin/bash
#SBATCH --job-name=gpu-benchmark
#SBATCH --partition=gpu
#SBATCH --qos=gpu_access
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=2
#SBATCH --mem=8G
#SBATCH --gres=gpu:1
#SBATCH --time=00:10:00
#SBATCH --output=slurm-%j.out
#SBATCH --error=slurm-%j.err

module load apptainer

echo "Job started on $(date)"
echo "Running on node: $(hostname)"
echo "Job ID: $SLURM_JOB_ID"

nvidia-smi

PYTHONPATH="" PYTHONNOUSERSITE=1 apptainer exec --no-home --nv stor674-benchmark_latest.sif python /app/compute_bench.py

echo "Job completed on $(date)"

```

**Grading Criteria:**
- Appropriate Slurm directives (#SBATCH) (4 points)
- Correct Apptainer run command (6 points)
- Output redirection and job organization (2 points)

## Question 3.4: Submit, Verify, and Version Control (3 points)

**a)** (1 point) What command did you use to submit your job to Slurm?

**Answer:**

```bash
# Command here
sbatch run_compute_bench.sh
```

**b)** (2 points) Provide the output of your job. Paste the contents of your Slurm output file (e.g., `slurm-jobid.out`). Also, add your Slurm script (`run_compute_bench.sh`) to your GitHub repository and push it.

**Job Output:**

```
[meihan03@longleaf-login1 stor674]$ cat slurm-22540528.out
Job started on Fri Nov 21 01:12:36 PM EST 2025
Running on node: g0601.ll.unc.edu
Job ID: 22540528
Fri Nov 21 13:12:36 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.95.05              Driver Version: 580.95.05      CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce GTX 1080        On  |   00000000:04:00.0 Off |                  N/A |
| 27%   28C    P8              6W /  180W |       3MiB /   8192MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
GPU available: NVIDIA GeForce GTX 1080

CPU Computations:
Time for 10,000,000 elements: 0.2131 seconds
Time for 100,000,000 elements: 1.5052 seconds

GPU Computations:
Time for 10,000,000 elements: 6.8171 seconds
Time for 100,000,000 elements: 0.0060 seconds

Small sample of 10 random numbers:
tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,
         0.4617,  0.2674])

Saved data to mydata.pt
Job completed on Fri Nov 21 01:12:54 PM EST 2025

```

**GitHub Verification:** ✓ Pushed `run_compute_bench.sh` to repository

**c)** (BONUS: +2 points) Include a screenshot showing your job in the Slurm queue or completed job information using `squeue` or `sacct`. Also show that your job successfully utilized a GPU (if you requested one).

```{r bonus, echo=FALSE, eval=TRUE}
knitr::include_graphics("/Users/zoraachen/Desktop/Fall 2025/STOR 674/HWs/stor674-homework5/bonusquestion.png")
```

---

# Part 4: Reflection and Best Practices (Optional - Extra Credit: 5 points)

**Question 4.1:** Reflect on the workflow you just completed (Git → Docker → HPC). How does this approach improve reproducibility in computational research? What are some advantages and potential challenges?

**Answer:**

The Git → Docker → HPC workflow significantly enhances reproducibility in computational research through several key mechanisms:

**Reproducibility Improvements:** 

- **Environment Consistency**: Docker containers encapsulate the entire computational environment (OS, libraries, dependencies, and specific package versions), ensuring that code runs identically across different systems. This eliminates the classic "works on my machine" problem.          

- **Version Control Integration**: Git tracks code changes while Docker Hub versions the environments, creating a complete historical record of both code and computational context.

- **Platform Independence**: The same container that runs on a developer's Mac laptop can run unchanged on Linux HPC clusters, enabling seamless development-to-production workflows.

**Advantages:**

1. **Simplified Collaboration**: Researchers can share a single Docker image instead of lengthy installation instructions, reducing setup time from hours to minutes.

2. **Scalability**: Once containerized, applications can easily scale from local testing to HPC clusters without modification.

3. **Preservation**: Archived containers preserve the exact computational environment, allowing research to be reproduced years later despite changing software landscapes.

4. **Isolation**: Containers prevent dependency conflicts between different projects on the same system.

**Challenges Encountered:**

- **Architecture Compatibility**: Building on ARM (Mac M1/M2) for x86_64 (HPC) requires careful cross-platform considerations and tools like buildx.

- **Technical Complexity**: Users need proficiency in multiple tools (Git, Docker, Apptainer, Slurm), creating a steep learning curve.

- **Environment Conflicts**: As we experienced, Python path conflicts between host and container environments can be tricky to debug and require specific isolation flags.

- **Storage Overhead**: Docker images can be large (our PyTorch image was ~3GB), consuming significant storage and bandwidth.

---

# Submission Checklist

Before submitting, make sure you have:

- [ ] Completed all questions in Part 1 (Git/GitHub concepts)
- [ ] **Created a GitHub repository with all your project files**
- [ ] **Practiced branching and merging in your Git workflow**
- [ ] Created a Dockerfile with CUDA support for GPU computing
- [ ] Built and tested your Docker image locally (Linux container on macOS/Windows)
- [ ] Pushed your image to Docker Hub
- [ ] Provided your Docker Hub image URL
- [ ] Created a Slurm job script
- [ ] Successfully ran your job on Longleaf
- [ ] **Pushed all files (Dockerfile, Slurm script, completed Rmd) to GitHub**
- [ ] Included all output and screenshots
- [ ] Compiled this Rmd file to HTML or PDF

**Submission Instructions:**

1. **Ensure your GitHub repository contains:**
   - `Dockerfile`
   - `compute_bench.py`
   - `run_compute_bench.sh` (Slurm script)
   - `Homework5.Rmd` (completed)
   - Evidence of branching/merging in commit history
   
2. Submit the knitted HTML/PDF file on Canvas
3. **Submit the link to your GitHub repository on Canvas (REQUIRED)**
4. Submit the link to your Docker Hub image on Canvas

---

# Grading Rubric

| Section | Points |
|---------|--------|
| Part 1: Git and GitHub Concepts | 20 |
| Part 2: Docker with Version Control (includes branching/merging) | 50 |
| Part 3: Apptainer and Slurm on Longleaf | 30 |
| **Total** | **100** |
| Extra Credit (Part 4: Reflection) | +5 |
| Extra Credit (Part 3.4c: GPU screenshot) | +2 |
| **Maximum Possible** | **107** |

---

# Resources

- [Git Branching Documentation](https://git-scm.com/book/en/v2/Git-Branching-Branches-in-a-Nutshell)
- [Docker Hub](https://hub.docker.com/)
- [Apptainer Documentation](https://apptainer.org/docs/)
- [Longleaf Documentation](https://help.rc.unc.edu/longleaf-cluster/)
- Course lecture materials on GitHub, Docker, and Apptainer

---

**Good luck!**

